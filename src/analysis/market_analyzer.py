import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import json
import os

from src.data.data_fetcher import StockDataFetcher
from src.analysis.stock_filter import StockFilter
from config.config import STOCK_FILTER_CONFIG, DATA_CONFIG

logger = logging.getLogger(__name__)

class MarketAnalyzer:
    def __init__(self):
        self.data_fetcher = StockDataFetcher()
        self.stock_filter = StockFilter()
        self.analysis_results = {}

    def _load_csi300_stocks(self) -> pd.DataFrame:
        """åŠ è½½æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ - ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜"""
        try:
            # æ–¹æ³•1: ä»æœ¬åœ°JSONæ–‡ä»¶åŠ è½½(å¿«é€Ÿ)
            local_file = './data/csi300_stocks.json'
            if os.path.exists(local_file):
                logger.info("ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨...")
                with open(local_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    stocks = data['stocks']
                    logger.info(f"æˆåŠŸä»æœ¬åœ°åŠ è½½ {len(stocks)} åªæ²ªæ·±300æˆåˆ†è‚¡ (æ›´æ–°æ—¥æœŸ: {data.get('update_date', 'æœªçŸ¥')})")
                    return pd.DataFrame(stocks)

            # æ–¹æ³•2: ä½¿ç”¨akshareåœ¨çº¿è·å–(æ…¢é€Ÿ,ä½œä¸ºå¤‡ç”¨)
            logger.warning("æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨,å°è¯•åœ¨çº¿è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨(å¯èƒ½è¾ƒæ…¢)...")
            import akshare as ak
            csi300_stocks = ak.index_stock_cons(symbol="000300")
            if not csi300_stocks.empty:
                logger.info(f"åœ¨çº¿è·å–æˆåŠŸ: {len(csi300_stocks)} åª")
                # ä¿å­˜åˆ°æœ¬åœ°ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
                result = pd.DataFrame({
                    'code': csi300_stocks['å“ç§ä»£ç '].tolist(),
                    'name': csi300_stocks['å“ç§åç§°'].tolist()
                })
                # ä¿å­˜åˆ°æœ¬åœ°
                os.makedirs('./data', exist_ok=True)
                save_data = {
                    'update_date': datetime.now().strftime('%Y-%m-%d'),
                    'note': 'æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ - è‡ªåŠ¨ç”Ÿæˆ',
                    'stocks': result.to_dict('records')
                }
                with open(local_file, 'w', encoding='utf-8') as f:
                    json.dump(save_data, f, ensure_ascii=False, indent=2)
                logger.info(f"å·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: {local_file}")
                return result

            logger.error("æ— æ³•è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨")
            return pd.DataFrame()

        except Exception as e:
            logger.error(f"åŠ è½½æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()

    def run_daily_analysis(self) -> Dict:
        """æ‰§è¡Œæ¯æ—¥ç›˜ååˆ†æ"""
        logger.info("å¼€å§‹æ‰§è¡Œç›˜ååˆ†æ...")

        try:
            # 1. è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼‰
            a_share_list = self._load_csi300_stocks()
            if a_share_list.empty:
                logger.error("æ— æ³•è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨")
                return {}

            logger.info(f"å¼€å§‹åˆ†ææ²ªæ·±300æˆåˆ†è‚¡ï¼Œå…± {len(a_share_list)} åª")

            # 3. æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®ï¼ˆåˆ†æ‰¹å¤„ç†ä»¥é¿å…è¯·æ±‚è¿‡å¤šï¼‰
            batch_size = 100
            all_stock_data = []

            for i in range(0, len(a_share_list), batch_size):
                batch = a_share_list.iloc[i:i+batch_size]['code'].tolist()
                logger.info(f"å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹è‚¡ç¥¨ï¼Œå…± {len(batch)} åª")

                batch_data = self.data_fetcher.batch_get_stock_data(batch)
                all_stock_data.extend(batch_data)

            logger.info(f"æˆåŠŸè·å– {len(all_stock_data)} åªè‚¡ç¥¨çš„æ•°æ®")

            # 4. ç­›é€‰è‚¡ç¥¨
            selected_stocks = self.stock_filter.select_top_stocks(all_stock_data)

            # 5. è·å–å¸‚åœºæ¦‚å†µ
            market_overview = self.data_fetcher.get_market_overview()

            # 6. ç”Ÿæˆåˆ†æç»“æœ
            analysis_result = {
                'analysis_date': datetime.now().strftime('%Y-%m-%d'),
                'analysis_time': datetime.now().strftime('%H:%M:%S'),
                'market_overview': market_overview,
                'selected_stocks': selected_stocks,
                'total_analyzed': len(all_stock_data),
                'selection_criteria': STOCK_FILTER_CONFIG,
                'summary': self._generate_analysis_summary(selected_stocks, market_overview)
            }

            # 7. ä¿å­˜åˆ†æç»“æœ
            self._save_analysis_result(analysis_result)

            # 8. è‡ªåŠ¨ç”ŸæˆMarkdownæŠ¥å‘Š
            self._generate_markdown_report(analysis_result)

            logger.info("ç›˜ååˆ†æå®Œæˆ")
            return analysis_result

        except Exception as e:
            logger.error(f"ç›˜ååˆ†æå¤±è´¥: {e}")
            return {}

    def _generate_analysis_summary(self, selected_stocks: List[Dict], market_overview: Dict) -> Dict:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        try:
            summary = {
                'market_sentiment': self._analyze_market_sentiment(market_overview),
                'stock_recommendations': [],
                'risk_warnings': [],
                'key_metrics': {}
            }

            # åˆ†æé€‰ä¸­çš„è‚¡ç¥¨
            for stock in selected_stocks:
                recommendation = {
                    'rank': stock.get('rank', 0),
                    'code': stock.get('code', ''),
                    'name': stock.get('name', ''),
                    'current_price': stock.get('price', 0),
                    'change_pct': stock.get('change_pct', 0),
                    'pe_ratio': stock.get('pe_ratio', 0),
                    'momentum_20d': stock.get('momentum_20d', 0),
                    'strength_score': stock.get('strength_score', 0),
                    'reason': stock.get('selection_reason', '')
                }
                summary['stock_recommendations'].append(recommendation)

            # å…³é”®æŒ‡æ ‡
            if selected_stocks:
                prices = [s.get('price', 0) for s in selected_stocks]
                pe_ratios = [s.get('pe_ratio', 0) for s in selected_stocks if s.get('pe_ratio', 0) > 0]
                momentums = [s.get('momentum_20d', 0) for s in selected_stocks]

                summary['key_metrics'] = {
                    'avg_price': np.mean(prices),
                    'avg_pe_ratio': np.mean(pe_ratios) if pe_ratios else 0,
                    'avg_momentum': np.mean(momentums),
                    'price_range': f"{min(prices):.2f} - {max(prices):.2f}",
                    'pe_range': f"{min(pe_ratios):.2f} - {max(pe_ratios):.2f}" if pe_ratios else "N/A"
                }

            # é£é™©æç¤º
            if market_overview.get('rising_ratio', 0) < 30:
                summary['risk_warnings'].append("å¸‚åœºæ•´ä½“è¡¨ç°è¾ƒå¼±ï¼Œæ³¨æ„æ§åˆ¶ä»“ä½")

            if any(s.get('pe_ratio', 0) > 25 for s in selected_stocks):
                summary['risk_warnings'].append("éƒ¨åˆ†æ¨èè‚¡ç¥¨PEè¾ƒé«˜ï¼Œæ³¨æ„ä¼°å€¼é£é™©")

            return summary

        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ†ææ‘˜è¦å¤±è´¥: {e}")
            return {}

    def _analyze_market_sentiment(self, market_overview: Dict) -> str:
        """åˆ†æå¸‚åœºæƒ…ç»ª"""
        try:
            rising_ratio = market_overview.get('rising_ratio', 0)
            avg_change = market_overview.get('avg_change_pct', 0)

            if rising_ratio > 70 and avg_change > 1:
                return "å¼ºåŠ¿ä¸Šæ¶¨"
            elif rising_ratio > 60 and avg_change > 0.5:
                return "åå¼ºéœ‡è¡"
            elif rising_ratio > 40:
                return "éœ‡è¡æ•´ç†"
            elif rising_ratio > 30:
                return "åå¼±è°ƒæ•´"
            else:
                return "å¼±åŠ¿ä¸‹è·Œ"

        except Exception as e:
            logger.error(f"åˆ†æå¸‚åœºæƒ…ç»ªå¤±è´¥: {e}")
            return "æœªçŸ¥"

    def _save_analysis_result(self, result: Dict) -> bool:
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs('./logs/analysis', exist_ok=True)

            # ä¿å­˜åˆ°æ–‡ä»¶
            filename = f"./logs/analysis/analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=str)

            logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
            return False

    def get_latest_analysis(self) -> Optional[Dict]:
        """è·å–æœ€æ–°çš„åˆ†æç»“æœ"""
        try:
            log_dir = './logs/analysis'
            if not os.path.exists(log_dir):
                return None

            # æŸ¥æ‰¾æœ€æ–°çš„åˆ†ææ–‡ä»¶
            analysis_files = [f for f in os.listdir(log_dir) if f.startswith('analysis_') and f.endswith('.json')]
            if not analysis_files:
                return None

            latest_file = max(analysis_files)
            filepath = os.path.join(log_dir, latest_file)

            with open(filepath, 'r', encoding='utf-8') as f:
                result = json.load(f)

            return result

        except Exception as e:
            logger.error(f"è·å–æœ€æ–°åˆ†æç»“æœå¤±è´¥: {e}")
            return None

    def generate_performance_report(self, days: int = 7) -> Dict:
        """ç”Ÿæˆè¡¨ç°æŠ¥å‘Š"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å›æµ‹åŠŸèƒ½ï¼Œåˆ†æè¿‡å»æ¨èè‚¡ç¥¨çš„è¡¨ç°
            # ç®€åŒ–å®ç°ï¼Œè¿”å›åŸºæœ¬ç»Ÿè®¡
            latest_analysis = self.get_latest_analysis()
            if not latest_analysis:
                return {}

            selected_stocks = latest_analysis.get('selected_stocks', [])
            current_data = []

            # è·å–å½“å‰ä»·æ ¼
            for stock in selected_stocks:
                current_stock_data = self.data_fetcher.get_stock_realtime_data(stock['code'])
                if current_stock_data:
                    current_data.append({
                        'code': stock['code'],
                        'name': stock['name'],
                        'original_price': stock['price'],
                        'current_price': current_stock_data['price'],
                        'performance': (current_stock_data['price'] / stock['price'] - 1) * 100
                    })

            report = {
                'report_date': datetime.now().strftime('%Y-%m-%d'),
                'analysis_date': latest_analysis.get('analysis_date'),
                'stock_performance': current_data,
                'summary': {
                    'total_stocks': len(current_data),
                    'avg_performance': np.mean([s['performance'] for s in current_data]) if current_data else 0,
                    'best_performer': max(current_data, key=lambda x: x['performance']) if current_data else None,
                    'worst_performer': min(current_data, key=lambda x: x['performance']) if current_data else None
                }
            }

            return report

        except Exception as e:
            logger.error(f"ç”Ÿæˆè¡¨ç°æŠ¥å‘Šå¤±è´¥: {e}")
            return {}
    def _generate_markdown_report(self, analysis_result: Dict) -> bool:
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        try:
            from datetime import datetime
            
            analysis_date = analysis_result.get('analysis_date', datetime.now().strftime('%Y-%m-%d'))
            selected_stocks = analysis_result.get('selected_stocks', [])
            total_analyzed = analysis_result.get('total_analyzed', 300)
            config = analysis_result.get('selection_criteria', {})
            market_overview = analysis_result.get('market_overview', {})
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            date_obj = datetime.strptime(analysis_date, '%Y-%m-%d')
            date_cn = date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥')
            
            # ç”ŸæˆMarkdownå†…å®¹
            md_content = f"""# ğŸ“Š {date_cn}æ²ªæ·±300æˆåˆ†è‚¡åˆ†æç»“æœ

## ğŸ” **åˆ†ææ¦‚å†µ**

### ğŸ“… **åŸºæœ¬ä¿¡æ¯**
- **åˆ†ææ—¥æœŸ**: {analysis_date}
- **åˆ†ææ—¶é—´**: {analysis_result.get('analysis_time', '--')}
- **æ•°æ®æº**: å®æ—¶äº¤æ˜“æ•°æ®
- **è‚¡ç¥¨æ± **: æ²ªæ·±300æˆåˆ†è‚¡
- **ç›®æ ‡è‚¡ç¥¨æ•°**: {total_analyzed}åª
- **ç­›é€‰æ¡ä»¶**: PE â‰¤ {config.get('max_pe_ratio', 30)}, æˆäº¤é¢ â‰¥ {config.get('min_turnover', 50000000)/10000:.0f}ä¸‡å…ƒ

## ğŸ† **Top {len(selected_stocks)} ç²¾é€‰è‚¡ç¥¨**

"""
            
            # æ·»åŠ æ¯åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
            for stock in selected_stocks:
                trend = "â†—" if stock.get('change_pct', 0) > 0 else "â†˜" if stock.get('change_pct', 0) < 0 else "â†’"
                md_content += f"""### #{stock.get('rank', 0)} {stock['name']} ({stock['code']}) [{trend}]
- **ä»·æ ¼**: Â¥{stock.get('price', 0):.2f}
- **æ¶¨è·Œå¹…**: {stock.get('change_pct', 0):+.2f}%
- **PE**: {stock.get('pe_ratio', 0):.2f}å€
- **å¼ºåŠ¿åˆ†æ•°**: {stock.get('strength_score', 0):.0f}åˆ†
"""
                
                # æ·»åŠ åˆ†é¡¹å¾—åˆ†
                score_detail = stock.get('strength_score_detail', {})
                if score_detail:
                    breakdown = score_detail.get('breakdown', {})
                    md_content += f"""- **åˆ†é¡¹å¾—åˆ†**:
  - æŠ€æœ¯é¢: {breakdown.get('technical', 0)}åˆ†
  - ä¼°å€¼: {breakdown.get('valuation', 0)}åˆ†
  - ç›ˆåˆ©èƒ½åŠ›: {breakdown.get('profitability', 0)}åˆ†
  - å®‰å…¨æ€§: {breakdown.get('safety', 0)}åˆ†
  - è‚¡æ¯: {breakdown.get('dividend', 0)}åˆ†
- **è¯„çº§**: {score_detail.get('grade', '')}
"""
                
                md_content += f"""- **é€‰æ‹©ç†ç”±**: {stock.get('selection_reason', 'ç¬¦åˆç­›é€‰æ¡ä»¶')}

"""
            
            # æ·»åŠ å€™é€‰è‚¡ç¥¨è¡¨æ ¼
            if selected_stocks:
                md_content += f"""## ğŸ“‹ **Top {len(selected_stocks)} å€™é€‰è‚¡ç¥¨**

| æ’å | è‚¡ç¥¨åç§° | ä»£ç  | PE | ROE | æ¶¨è·Œå¹… | è¯„åˆ† | è¯„çº§ | æŠ€æœ¯é¢ | ä¼°å€¼ | ç›ˆåˆ© | å®‰å…¨ | è‚¡æ¯ | æˆäº¤é¢(ä¸‡) |
|------|----------|------|----|----- |---------|------|------|--------|------|------|------|------|-----------|
"""

                for stock in selected_stocks:
                    turnover_display = f"{stock.get('turnover', 0):.0f}" if stock.get('turnover') else "-"
                    roe_display = f"{stock.get('roe', 0):.1f}%" if stock.get('roe') else "-"
                    grade = stock.get('strength_grade', '-')
                    
                    # è·å–åˆ†é¡¹å¾—åˆ†
                    score_detail = stock.get('strength_score_detail', {})
                    tech_score = 0
                    val_score = 0
                    prof_score = 0
                    safe_score = 0
                    div_score = 0
                    if score_detail:
                        breakdown = score_detail.get('breakdown', {})
                        tech_score = breakdown.get('technical', 0)
                        val_score = breakdown.get('valuation', 0)
                        prof_score = breakdown.get('profitability', 0)
                        safe_score = breakdown.get('safety', 0)
                        div_score = breakdown.get('dividend', 0)
                    
                    md_content += f"|  {stock.get('rank', 0)} | {stock['name']} | {stock['code']} | {stock.get('pe_ratio', 0):.2f} | {roe_display} | {stock.get('change_pct', 0):+.2f}% | {stock.get('strength_score', 0):.0f} | {grade} | {tech_score} | {val_score} | {prof_score} | {safe_score} | {div_score} | {turnover_display} |\n"
            
            # æ·»åŠ ç­›é€‰ç»Ÿè®¡
            md_content += f"""
## ğŸ“Š **æ²ªæ·±300ç­›é€‰ç»Ÿè®¡**

### ğŸ” **ç­›é€‰ç»“æœ**
- **æ²ªæ·±300æ€»æ•°**: {total_analyzed}åª
- **ç­›é€‰é€šè¿‡**: {len(selected_stocks)}åª
- **ç­›é€‰é€šè¿‡ç‡**: {len(selected_stocks)/total_analyzed*100 if total_analyzed > 0 else 0:.2f}%

### ğŸ“Š **ç­›é€‰æ ‡å‡†**
- **PEç­›é€‰**: PE â‰¤ {config.get('max_pe_ratio', 30)}
- **æˆäº¤é¢ç­›é€‰**: æˆäº¤é¢ â‰¥ {config.get('min_turnover', 50000000)/10000:.0f}ä¸‡å…ƒ
- **å¼ºåŠ¿åˆ†æ•°**: â‰¥ {config.get('min_strength_score', 50)}
- **æ•°é‡é™åˆ¶**: æœ€å¤šæ¨è{config.get('max_stocks', 3)}åªè‚¡ç¥¨

## ğŸ“Š **å¸‚åœºç»Ÿè®¡**

### ğŸ¯ **æ•´ä½“è¡¨ç°**
- **å…¨å¸‚åœºæ€»è‚¡ç¥¨**: {market_overview.get('total_stocks', 0):,}åª
- **ä¸Šæ¶¨è‚¡ç¥¨**: {market_overview.get('rising_stocks', 0):,}åª ({market_overview.get('rising_ratio', 0):.2f}%)
- **ä¸‹è·Œè‚¡ç¥¨**: {market_overview.get('falling_stocks', 0):,}åª
- **å…¨å¸‚åœºå¹³å‡æ¶¨è·Œå¹…**: {market_overview.get('avg_change_pct', 0):.2f}%
- **å¸‚åœºæƒ…ç»ª**: {analysis_result.get('summary', {}).get('market_sentiment', 'æœªçŸ¥')}

## ğŸ¯ **æŠ•èµ„åˆ†æ**

### âœ… **ç²¾é€‰è‚¡ç¥¨äº®ç‚¹**
"""
            
            for i, stock in enumerate(selected_stocks, 1):
                # è·å–åˆ†é¡¹å¾—åˆ†ä¸­çš„æœ€é«˜åˆ†
                score_detail = stock.get('strength_score_detail', {})
                max_score_name = ""
                max_score_value = 0
                if score_detail:
                    breakdown = score_detail.get('breakdown', {})
                    score_items = [
                        ("æŠ€æœ¯é¢", breakdown.get('technical', 0)),
                        ("ä¼°å€¼", breakdown.get('valuation', 0)),
                        ("ç›ˆåˆ©èƒ½åŠ›", breakdown.get('profitability', 0)),
                        ("å®‰å…¨æ€§", breakdown.get('safety', 0)),
                        ("è‚¡æ¯", breakdown.get('dividend', 0))
                    ]
                    max_score_name, max_score_value = max(score_items, key=lambda x: x[1])
                
                md_content += f"""
{i}. **{stock['name']} ({stock['code']})**
   - **ä¼°å€¼æ°´å¹³**: PE {stock.get('pe_ratio', 0):.2f}å€
   - **å¼ºåŠ¿è¯„åˆ†**: {stock.get('strength_score', 0):.0f}åˆ†
   - **ä¼˜åŠ¿ç»´åº¦**: {max_score_name} ({max_score_value}åˆ†)
"""
            
            md_content += f"""
### ğŸ“ˆ **æŠ•èµ„ä»·å€¼**
- **å¸‚åœºä»£è¡¨æ€§**: åŸºäºæ²ªæ·±300æˆåˆ†è‚¡,ä»£è¡¨Aè‚¡æ ¸å¿ƒä¼˜è´¨èµ„äº§
- **ä¼°å€¼å®‰å…¨**: ä¸¥æ ¼PEç­›é€‰é¿å…é«˜é£é™©æ ‡çš„  
- **æµåŠ¨æ€§ä¿è¯**: æˆäº¤é¢è¦æ±‚ç¡®ä¿å……è¶³çš„äº¤æ˜“æµåŠ¨æ€§
- **æŠ€æœ¯ç­›é€‰**: åŸºäº20æ—¥åŠ¨é‡ã€å¼ºåŠ¿åˆ†æ•°ç­‰å¤šç»´åº¦æŠ€æœ¯æŒ‡æ ‡

### âš ï¸ **é£é™©æç¤º**
1. **å¸‚åœºé£é™©**: è‚¡å¸‚æœ‰é£é™©,æŠ•èµ„éœ€è°¨æ…
2. **ä¼°å€¼é£é™©**: PEä¸ºå†å²æ•°æ®,éœ€å…³æ³¨æœ€æ–°è´¢æŠ¥
3. **æµåŠ¨æ€§é£é™©**: å¸‚åœºæ³¢åŠ¨å¯èƒ½å½±å“äº¤æ˜“æµåŠ¨æ€§
4. **æŠ•èµ„å»ºè®®**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒ,ä¸æ„æˆæŠ•èµ„å»ºè®®

## ğŸ’¡ **æŠ€æœ¯è¯´æ˜**

### ğŸ”§ **ç­–ç•¥ç‰¹ç‚¹**
- **å¤šç»´åº¦ç­›é€‰**: PEä¼°å€¼ã€æˆäº¤é¢ã€åŠ¨é‡ã€å¼ºåŠ¿è¯„åˆ†ç»¼åˆè¯„ä¼°
- **20æ—¥åŠ¨é‡**: åŸºäº20æ—¥ä»·æ ¼åŠ¨é‡æ•æ‰è¶‹åŠ¿
- **æˆäº¤é¢è¿‡æ»¤**: ç¡®ä¿è¶³å¤Ÿçš„å¸‚åœºæµåŠ¨æ€§
- **æ™ºèƒ½è¯„åˆ†**: ç»¼åˆæ¶¨è·Œå¹…ã€åŠ¨é‡ã€æµåŠ¨æ€§ç­‰æŒ‡æ ‡

### ğŸ“Š **æ•°æ®æ¥æº**
- **è‚¡ç¥¨æ± **: æ²ªæ·±300æˆåˆ†è‚¡
- **æ•°æ®é¢‘ç‡**: å®æ—¶äº¤æ˜“æ•°æ®
- **æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**åˆ†æç‰ˆæœ¬**: v3.0 (é‡åŒ–ç­–ç•¥ä¼˜åŒ–ç‰ˆ)
**æ•°æ®èŒƒå›´**: æ²ªæ·±300æˆåˆ†è‚¡åˆ†æ âœ“
"""
            
            # ç¡®ä¿reportsç›®å½•å­˜åœ¨
            os.makedirs('./reports', exist_ok=True)

            # ä¿å­˜æ–‡ä»¶
            output_file = f"./reports/{date_cn}æ²ªæ·±300åˆ†æç»“æœ.md"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(md_content)

            logger.info(f"MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {e}")
            return False
